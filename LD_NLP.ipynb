{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LD_NLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlR21LNCQANMJj4tvT/+vf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inamdarmihir/researchdocs/blob/main/LD_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the libraries:"
      ],
      "metadata": {
        "id": "1IxLxIMaFDRr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CEH5JVM9FAhs"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "import codecs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import feature_extraction\n",
        "from sklearn import linear_model\n",
        "from sklearn import pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nlp\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "import nlp\n",
        "import random\n",
        "\n",
        "\n",
        "def show_history(h):\n",
        "    epochs_trained = len(h.history['loss'])\n",
        "    plt.figure(figsize=(16, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(0, epochs_trained), h.history.get('accuracy'), label='Training')\n",
        "    plt.plot(range(0, epochs_trained), h.history.get('val_accuracy'), label='Validation')\n",
        "    plt.ylim([0., 1.])\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(0, epochs_trained), h.history.get('loss'), label='Training')\n",
        "    plt.plot(range(0, epochs_trained), h.history.get('val_loss'), label='Validation')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "def show_confusion_matrix(y_true, y_pred, classes):\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    \n",
        "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    sp = plt.subplot(1, 1, 1)\n",
        "    ctx = sp.matshow(cm)\n",
        "    plt.xticks(list(range(0, 6)), labels=classes)\n",
        "    plt.yticks(list(range(0, 6)), labels=classes)\n",
        "    plt.colorbar(ctx)\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "print('Using TensorFlow version', tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTQjse8eFDBx",
        "outputId": "313bde73-e936-4b8a-deb7-31db87a212a7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nlp in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from nlp) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from nlp) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from nlp) (0.3.5.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from nlp) (3.0.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from nlp) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nlp) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nlp) (1.3.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from nlp) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nlp) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nlp) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->nlp) (1.15.0)\n",
            "Using TensorFlow version 2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loaing the Data:"
      ],
      "metadata": {
        "id": "UZXOP2BaFbhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"Language Detection.csv\")\n",
        "data[\"Language\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_2xacmXFbOd",
        "outputId": "65a58c21-ad29-4fb4-efe5-cfe28b5267bf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "English       1385\n",
              "French        1014\n",
              "Spanish        819\n",
              "Portugeese     739\n",
              "Italian        698\n",
              "Russian        692\n",
              "Sweedish       676\n",
              "Malayalam      594\n",
              "Dutch          546\n",
              "Arabic         536\n",
              "Turkish        474\n",
              "German         470\n",
              "Tamil          469\n",
              "Danish         428\n",
              "Kannada        369\n",
              "Greek          365\n",
              "Hindi           63\n",
              "Name: Language, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Separating Independent and Dependent features\n",
        "X = data[\"Text\"]\n",
        "y = data[\"Language\"]\n",
        "\n",
        "#Label Encoding to convert it into a numerical form\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "KbU5zqAQGkqm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data pre-processing:"
      ],
      "metadata": {
        "id": "iEUdyNNkFs0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for char in string.punctuation:\n",
        "  print(char, end=\" \")\n",
        "translate_table = dict((ord(char), None) for char in string.punctuation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JPbf1t_Fq5Z",
        "outputId": "1d9d2288-140a-447c-c5e1-8979c02d3639"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "! \" # $ % & ' ( ) * + , - . / : ; < = > ? @ [ \\ ] ^ _ ` { | } ~ "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = []\n",
        "\n",
        "\n",
        "# iterating through all the text\n",
        "for text in X:         \n",
        "    text = re.sub(r'[!@#$(),n\"%^*?:;~`0-9]', ' ', text)      # removing the symbols and numbers\n",
        "    text = re.sub(r'[[]]', ' ', text)   \n",
        "    text = text.lower()          # converting the text to lower case\n",
        "    data_list.append(text)"
      ],
      "metadata": {
        "id": "-V_cx1nSFx8V"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizer and Model Fitting Pipeline:"
      ],
      "metadata": {
        "id": "Hhjks69oGr90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = feature_extraction.text.TfidfVectorizer(ngram_range=(1,3), analyzer = 'char')\n",
        "\n",
        "pipe_lr_r13 = pipeline.Pipeline([('vectorizer', vectorizer),\n",
        "                                 ('clf', linear_model.LogisticRegression())])"
      ],
      "metadata": {
        "id": "yUsWVfgiGnkq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Fitting/Training:"
      ],
      "metadata": {
        "id": "2wDKXYC5Gyqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=42)\n",
        "\n",
        "#Model Fitting:\n",
        "pipe_lr_r13.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dpKXluDGnoA",
        "outputId": "ef58edb0-bb55-4fce-bce2-af90ee4e7ec0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='char', ngram_range=(1, 3))),\n",
              "                ('clf', LogisticRegression())])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Predicition/Evaluation:"
      ],
      "metadata": {
        "id": "PMH1OS6rHgXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#predict output for test dataset\n",
        "y_pred = pipe_lr_r13.predict(x_test)"
      ],
      "metadata": {
        "id": "k3R56V6WHFld"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "ac = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "#Printing the accuracy:\n",
        "print(\"Accuracy is :\",ac)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM-N99DKHe2d",
        "outputId": "1312dc6c-c401-4b27-f7db-c08b7fbdebdf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is : 0.9840425531914894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix : \\n\",matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2J6-F5mH-3x",
        "outputId": "2dc2a1ae-1cf6-4660-bd93-9031daeda76c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix : \n",
            " [[106   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0  71   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0]\n",
            " [  0   0 107   3   0   1   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 290   0   0   0   0   0   0   0   0   0   0   0   0   1]\n",
            " [  0   0   0   2 215   0   0   0   1   0   0   1   0   0   0   0   0]\n",
            " [  0   0   2   1   0  89   0   0   0   0   0   0   0   0   1   0   0]\n",
            " [  0   0   0   0   0   0  68   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  10   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   1   0   0   0   0 141   0   0   0   0   1   0   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0  66   0   0   0   0   0   0   0]\n",
            " [  0   0   0   1   0   0   0   0   0   0 120   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   1   0   0 141   0   1   0   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 136   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   1   0   0   2   1 156   0   0   0]\n",
            " [  0   2   0   2   1   0   0   0   0   0   0   0   0   0 128   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  87   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0 104]]\n"
          ]
        }
      ]
    }
  ]
}